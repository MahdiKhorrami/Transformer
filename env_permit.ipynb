{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38ad8608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "import argparse\n",
    "import pm4py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics \n",
    "\n",
    "from processtransformer import constants\n",
    "from processtransformer.models import transformer\n",
    "from processtransformer.data.loader import LogsDataLoader\n",
    "from processtransformer.data.processor import LogsDataProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed46a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb75f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1391894c39e24a53895546920dadd5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/1434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_file_path= \"env_permit.xes.gz\"\n",
    "output_file_path='./datasets/env_permit.csv'\n",
    "\n",
    "#Write to Pandas Dataframe\n",
    "log = pm4py.read_xes(input_file_path) #Input Filename\n",
    "df = pm4py.convert_to_dataframe(log)\n",
    "df.to_csv(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2684a27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org:resource</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>case:REG_DATE</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>case:AMOUNT_REQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2011-09-30 22:38:44.546000+00:00</td>\n",
       "      <td>2011-09-30 22:38:44.546000+00:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-09-30 22:38:44.880000+00:00</td>\n",
       "      <td>2011-09-30 22:38:44.546000+00:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2011-09-30 22:39:37.906000+00:00</td>\n",
       "      <td>2011-09-30 22:38:44.546000+00:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112</td>\n",
       "      <td>SCHEDULE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-09-30 22:39:38.875000+00:00</td>\n",
       "      <td>2011-09-30 22:38:44.546000+00:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>START</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 09:36:46.437000+00:00</td>\n",
       "      <td>2011-09-30 22:38:44.546000+00:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262195</th>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2012-02-29 22:51:17.423000+00:00</td>\n",
       "      <td>2012-02-29 22:51:16.799000+00:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262196</th>\n",
       "      <td>112</td>\n",
       "      <td>SCHEDULE</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2012-02-29 22:52:01.287000+00:00</td>\n",
       "      <td>2012-02-29 22:51:16.799000+00:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262197</th>\n",
       "      <td>11169</td>\n",
       "      <td>START</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2012-03-01 08:26:46.736000+00:00</td>\n",
       "      <td>2012-02-29 22:51:16.799000+00:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262198</th>\n",
       "      <td>11169</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>2012-03-01 08:27:37.118000+00:00</td>\n",
       "      <td>2012-02-29 22:51:16.799000+00:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262199</th>\n",
       "      <td>11169</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2012-03-01 08:27:41.325000+00:00</td>\n",
       "      <td>2012-02-29 22:51:16.799000+00:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262200 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       org:resource lifecycle:transition            concept:name  \\\n",
       "0               112             COMPLETE             A_SUBMITTED   \n",
       "1               112             COMPLETE       A_PARTLYSUBMITTED   \n",
       "2               112             COMPLETE           A_PREACCEPTED   \n",
       "3               112             SCHEDULE  W_Completeren aanvraag   \n",
       "4               NaN                START  W_Completeren aanvraag   \n",
       "...             ...                  ...                     ...   \n",
       "262195          112             COMPLETE       A_PARTLYSUBMITTED   \n",
       "262196          112             SCHEDULE      W_Afhandelen leads   \n",
       "262197        11169                START      W_Afhandelen leads   \n",
       "262198        11169             COMPLETE              A_DECLINED   \n",
       "262199        11169             COMPLETE      W_Afhandelen leads   \n",
       "\n",
       "                         time:timestamp                    case:REG_DATE  \\\n",
       "0      2011-09-30 22:38:44.546000+00:00 2011-09-30 22:38:44.546000+00:00   \n",
       "1      2011-09-30 22:38:44.880000+00:00 2011-09-30 22:38:44.546000+00:00   \n",
       "2      2011-09-30 22:39:37.906000+00:00 2011-09-30 22:38:44.546000+00:00   \n",
       "3      2011-09-30 22:39:38.875000+00:00 2011-09-30 22:38:44.546000+00:00   \n",
       "4      2011-10-01 09:36:46.437000+00:00 2011-09-30 22:38:44.546000+00:00   \n",
       "...                                 ...                              ...   \n",
       "262195 2012-02-29 22:51:17.423000+00:00 2012-02-29 22:51:16.799000+00:00   \n",
       "262196 2012-02-29 22:52:01.287000+00:00 2012-02-29 22:51:16.799000+00:00   \n",
       "262197 2012-03-01 08:26:46.736000+00:00 2012-02-29 22:51:16.799000+00:00   \n",
       "262198 2012-03-01 08:27:37.118000+00:00 2012-02-29 22:51:16.799000+00:00   \n",
       "262199 2012-03-01 08:27:41.325000+00:00 2012-02-29 22:51:16.799000+00:00   \n",
       "\n",
       "       case:concept:name case:AMOUNT_REQ  \n",
       "0                 173688           20000  \n",
       "1                 173688           20000  \n",
       "2                 173688           20000  \n",
       "3                 173688           20000  \n",
       "4                 173688           20000  \n",
       "...                  ...             ...  \n",
       "262195            214376           15000  \n",
       "262196            214376           15000  \n",
       "262197            214376           15000  \n",
       "262198            214376           15000  \n",
       "262199            214376           15000  \n",
       "\n",
       "[262200 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deeff2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = LogsDataProcessor(name='env_permit', filepath=\"datasets/env_permit.csv\",  \n",
    "                                    columns = [\"case:concept:name\", \"concept:name\", \"time:timestamp\"], #specify the columns name containing case_id, activity name and timestamp \n",
    "                                    dir_path='datasets', pool = 4)\n",
    "data_processor.process_logs(task=constants.Task.NEXT_ACTIVITY, sort_temporally= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9054215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_loader = LogsDataLoader(name = 'env_permit')\n",
    "\n",
    "(train_df, test_df, x_word_dict, y_word_dict, max_case_length, \n",
    "    vocab_size, num_output) = data_loader.load_data(constants.Task.NEXT_ACTIVITY)\n",
    "\n",
    "# Prepare training examples for next activity prediction task\n",
    "train_token_x, train_token_y = data_loader.prepare_data_next_activity(train_df, \n",
    "    x_word_dict, y_word_dict, max_case_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c88eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 12\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f4d5f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 50s 22ms/step - loss: 1.3410 - sparse_categorical_accuracy: 0.5574\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 11s 22ms/step - loss: 0.6525 - sparse_categorical_accuracy: 0.8097\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 11s 22ms/step - loss: 0.5710 - sparse_categorical_accuracy: 0.8289\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 10s 20ms/step - loss: 0.5340 - sparse_categorical_accuracy: 0.8376\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 11s 22ms/step - loss: 0.5082 - sparse_categorical_accuracy: 0.8455\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 11s 22ms/step - loss: 0.4911 - sparse_categorical_accuracy: 0.8445\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 11s 22ms/step - loss: 0.4807 - sparse_categorical_accuracy: 0.8499\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 12s 24ms/step - loss: 0.4783 - sparse_categorical_accuracy: 0.8491\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 11s 23ms/step - loss: 0.4637 - sparse_categorical_accuracy: 0.8484\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 11s 23ms/step - loss: 0.4636 - sparse_categorical_accuracy: 0.8517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227e7c3e7f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train a transformer model\n",
    "transformer_model = transformer.get_next_activity_model(\n",
    "    max_case_length=max_case_length, \n",
    "    vocab_size=vocab_size,\n",
    "    output_dim=num_output)\n",
    "\n",
    "transformer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "transformer_model.fit(train_token_x, train_token_y, \n",
    "    epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e1730b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 15ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 18ms/step\n",
      "8/8 [==============================] - 1s 25ms/step\n",
      "8/8 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate over all the prefixes (k) and save the results\n",
    "k, accuracies,fscores, precisions, recalls = [],[],[],[],[]\n",
    "for i in range(max_case_length):\n",
    "    test_data_subset = test_df[test_df[\"k\"]==i]\n",
    "    if len(test_data_subset) > 0:\n",
    "        test_token_x, test_token_y = data_loader.prepare_data_next_activity(test_data_subset, \n",
    "            x_word_dict, y_word_dict, max_case_length)   \n",
    "        y_pred = np.argmax(transformer_model.predict(test_token_x), axis=1)\n",
    "        accuracy = metrics.accuracy_score(test_token_y, y_pred)\n",
    "        precision, recall, fscore, _ = metrics.precision_recall_fscore_support(\n",
    "            test_token_y, y_pred, average=\"weighted\")\n",
    "        k.append(i)\n",
    "        accuracies.append(accuracy)\n",
    "        fscores.append(fscore)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "k.append(i + 1)\n",
    "accuracies.append(np.mean(accuracy))\n",
    "fscores.append(np.mean(fscores))\n",
    "precisions.append(np.mean(precisions))\n",
    "recalls.append(np.mean(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e954582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy across all prefixes: 0.8969673057396751\n",
      "Average f-score across all prefixes: 0.8537354865890737\n",
      "Average precision across all prefixes: 0.8344194569900676\n",
      "Average recall across all prefixes: 0.8855192285996389\n"
     ]
    }
   ],
   "source": [
    "print('Average accuracy across all prefixes:', np.mean(accuracies))\n",
    "print('Average f-score across all prefixes:', np.mean(fscores))\n",
    "print('Average precision across all prefixes:', np.mean(precisions))\n",
    "print('Average recall across all prefixes:', np.mean(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1589b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f7518d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = LogsDataProcessor(name='env_permit', filepath=\"datasets/env_permit.csv\",  \n",
    "                                    columns = [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],  #specify the columns name containing case_id, activity name and timestamp \n",
    "                                    dir_path='datasets', pool = 4)\n",
    "data_processor.process_logs(task=constants.Task.NEXT_TIME, sort_temporally= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b08d03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_loader = LogsDataLoader(name = 'env_permit')\n",
    "\n",
    "(train_df, test_df, x_word_dict, y_word_dict, max_case_length, \n",
    "    vocab_size, num_output) = data_loader.load_data(constants.Task.NEXT_TIME)\n",
    "\n",
    "# Prepare training examples for next time prediction task\n",
    "(train_token_x, train_time_x, train_token_y, time_scaler, y_scaler) = \\\n",
    "                                    data_loader.prepare_data_next_time(train_df, x_word_dict, max_case_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c26ddb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 12\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4cb4882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 - 52s - loss: 0.1065 - 52s/epoch - 89ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227e795d8b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train a transformer model\n",
    "transformer_model = transformer.get_next_time_model(\n",
    "        max_case_length=max_case_length, \n",
    "        vocab_size=vocab_size)\n",
    "\n",
    "transformer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "        loss=tf.keras.losses.LogCosh())\n",
    "\n",
    "transformer_model.fit([train_token_x, train_time_x], train_token_y, \n",
    "        epochs=epochs, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d75b7952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 3s 18ms/step\n",
      "8/8 [==============================] - 0s 15ms/step\n",
      "8/8 [==============================] - 0s 15ms/step\n",
      "8/8 [==============================] - 0s 15ms/step\n",
      "8/8 [==============================] - 0s 15ms/step\n",
      "8/8 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate over all the prefixes (k) and save the results\n",
    "k, maes, mses, rmses = [],[],[],[]\n",
    "for i in range(max_case_length):\n",
    "    test_data_subset = test_df[test_df[\"k\"]==i]\n",
    "    if len(test_data_subset) > 0:\n",
    "        test_token_x, test_time_x, test_y, _, _ = data_loader.prepare_data_next_time(\n",
    "            test_data_subset, x_word_dict, max_case_length, time_scaler, y_scaler, False)   \n",
    "\n",
    "        y_pred = transformer_model.predict([test_token_x, test_time_x])\n",
    "        _test_y = y_scaler.inverse_transform(test_y)\n",
    "        _y_pred = y_scaler.inverse_transform(y_pred)\n",
    "\n",
    "        k.append(i)\n",
    "        maes.append(metrics.mean_absolute_error(_test_y, _y_pred))\n",
    "        mses.append(metrics.mean_squared_error(_test_y, _y_pred))\n",
    "        rmses.append(np.sqrt(metrics.mean_squared_error(_test_y, _y_pred)))\n",
    "\n",
    "k.append(i + 1)\n",
    "maes.append(np.mean(maes))\n",
    "mses.append(np.mean(mses))\n",
    "rmses.append(np.mean(rmses))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f46861cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE across all prefixes: 0.5810005\n",
      "Average MSE across all prefixes: 7.0397906\n",
      "Average RMSE across all prefixes: 2.1336849\n"
     ]
    }
   ],
   "source": [
    "print('Average MAE across all prefixes:', np.mean(maes))\n",
    "print('Average MSE across all prefixes:', np.mean(mses))\n",
    "print('Average RMSE across all prefixes:', np.mean(rmses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0481ac2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0035967",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = LogsDataProcessor(name='env_permit', filepath=\"datasets/env_permit.csv\",  \n",
    "                                    columns = [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],  #specify the columns name containing case_id, activity name and timestamp \n",
    "                                    dir_path='datasets', pool = 4)\n",
    "data_processor.process_logs(task=constants.Task.REMAINING_TIME, sort_temporally= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b25fc664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_loader = LogsDataLoader(name = 'env_permit')\n",
    "\n",
    "(train_df, test_df, x_word_dict, y_word_dict, max_case_length, \n",
    "    vocab_size, num_output) = data_loader.load_data(constants.Task.REMAINING_TIME)\n",
    "\n",
    "# Prepare training examples for next time prediction task\n",
    "(train_token_x, train_time_x, \n",
    "    train_token_y, time_scaler, y_scaler) = data_loader.prepare_data_remaining_time(train_df, \n",
    "    x_word_dict, max_case_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "feb861ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 12\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81ea2565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 - 56s - loss: 0.1693 - 56s/epoch - 96ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227ecd194f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train a transformer model\n",
    "transformer_model = transformer.get_remaining_time_model(\n",
    "    max_case_length=max_case_length, \n",
    "    vocab_size=vocab_size)\n",
    "\n",
    "transformer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "    loss=tf.keras.losses.LogCosh())\n",
    "\n",
    "transformer_model.fit([train_token_x, train_time_x], train_token_y, \n",
    "        epochs=epochs, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e27994f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 3s 20ms/step\n",
      "8/8 [==============================] - 0s 17ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 18ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate over all the prefixes (k) and save the results\n",
    "k, maes, mses, rmses = [],[],[],[]\n",
    "for i in range(max_case_length):\n",
    "    test_data_subset = test_df[test_df[\"k\"]==i]\n",
    "    if len(test_data_subset) > 0:\n",
    "        test_token_x, test_time_x, test_y, _, _ = data_loader.prepare_data_remaining_time(\n",
    "            test_data_subset, x_word_dict, max_case_length, time_scaler, y_scaler, False)   \n",
    "\n",
    "        y_pred = transformer_model.predict([test_token_x, test_time_x])\n",
    "        _test_y = y_scaler.inverse_transform(test_y)\n",
    "        _y_pred = y_scaler.inverse_transform(y_pred)\n",
    "\n",
    "        k.append(i)\n",
    "        maes.append(metrics.mean_absolute_error(_test_y, _y_pred))\n",
    "        mses.append(metrics.mean_squared_error(_test_y, _y_pred))\n",
    "        rmses.append(np.sqrt(metrics.mean_squared_error(_test_y, _y_pred)))\n",
    "\n",
    "k.append(i + 1)\n",
    "maes.append(np.mean(maes))\n",
    "mses.append(np.mean(mses))\n",
    "rmses.append(np.mean(rmses))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74c295ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE across all prefixes: 2.030811\n",
      "Average MSE across all prefixes: 31.255884\n",
      "Average RMSE across all prefixes: 4.972112\n"
     ]
    }
   ],
   "source": [
    "print('Average MAE across all prefixes:', np.mean(maes))\n",
    "print('Average MSE across all prefixes:', np.mean(mses))\n",
    "print('Average RMSE across all prefixes:', np.mean(rmses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bed15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f484cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
